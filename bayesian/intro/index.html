<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">

    
    <title>Introdu√ß√£o - Teaching Assistance</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../css/base.min.css" rel="stylesheet">
    <link href="../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../..">Teaching Assistance</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Gradua√ß√£o <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../alglin/info/">√Ålgebra Linear</a>
</li>

                        
                            
<li >
    <a href="../../analisenum/info/">An√°lise Num√©rica</a>
</li>

                        
                            
<li >
    <a href="../../curvas/info/">Curvas</a>
</li>

                        
                            
<li >
    <a href="../../edo/info/">Equa√ß√µes Diferenciais Ordin√°rias</a>
</li>

                        
                            
<li >
    <a href="../../edp/info/">Equa√ß√µes Diferenciais Parciais</a>
</li>

                        
                            
<li >
    <a href="../../infestatistica_BSc/info/">Infer√™ncia Estat√≠stica</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">P√≥s-gradua√ß√£o <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../functional_analysis/info/">An√°lise Funcional</a>
</li>

                        
                            
<li >
    <a href="../info/">Estat√≠stica Bayesiana</a>
</li>

                        
                            
<li >
    <a href="../../infestatistica_MSc/info/">Infer√™ncia Estat√≠stica</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li>
                        <a href="https://lucasmoschen.github.io">P√°gina Inicial</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#introducao">Introdu√ß√£o</a></li>
            <li class="second-level"><a href="#modelo-parametrico">Modelo param√©trico</a></li>
                
            <li class="second-level"><a href="#paradigma-bayesiano">Paradigma bayesiano</a></li>
                
                <li class="third-level"><a href="#teorema-de-bayes">Teorema de Bayes</a></li>
            <li class="second-level"><a href="#um-pouco-de-historia">Um pouco de hist√≥ria</a></li>
                
            <li class="second-level"><a href="#visao-subjetiva-da-probabilidade">Vis√£o subjetiva da probabilidade</a></li>
                
            <li class="second-level"><a href="#principio-da-verossimilhanca-e-principio-da-suficiencia">Princ√≠pio da Verossimilhan√ßa e Princ√≠pio da Sufici√™ncia</a></li>
                
                <li class="third-level"><a href="#suficiencia">Sufici√™ncia</a></li>
                <li class="third-level"><a href="#principio-da-verossimilhanca">Princ√≠pio da Verossimilhan√ßa</a></li>
                <li class="third-level"><a href="#derivando-o-principio-da-verossimilhanca">Derivando o princ√≠pio da verossimilhan√ßa</a></li>
            <li class="second-level"><a href="#distribuicoes-a-priori-e-a-posteriori">Distribui√ß√µes a priori e a posteriori</a></li>
                
                <li class="third-level"><a href="#distribuicoes-a-priori-improprias">Distribui√ß√µes a priori impr√≥prias</a></li>
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="introducao">Introdu√ß√£o</h1>
<ul>
<li>
<p><strong>Teoria Estat√≠stica</strong>: objetiva obter uma infer√™ncia sobre a distribui√ß√£o de probabilidade de um fen√¥meno a partir de observa√ß√µes. </p>
</li>
<li>
<p>A base te√≥rica do livro <em>The Bayesian Choice</em> √© constru√≠da sob o ponto de vista da Teoria da Decis√£o. Isso se deve a dois fatores: <script type="math/tex">(I)</script> a infer√™ncia tem algum objetivo, isto √©, alguma decis√£o √© tomada baseada em uma previs√£o ou an√°lise, e ela tem consequ√™ncias mensur√°veis; e <script type="math/tex">(II)</script> a decis√£o clarifica a prefer√™ncia do estat√≠stico.</p>
</li>
<li>
<p>Estat√≠stica √© mais sobre a interpreta√ß√£o de fen√¥menos naturais do que a explica√ß√£o sobre eles. Al√©m disso, ela tem um passo de <em>formaliza√ß√£o redutiva</em>. </p>
</li>
<li>
<p>A modelagem estat√≠stica, atrav√©s probabilidade, possibilita incluir a informa√ß√£o dispon√≠vel sobre o fen√¥meno e a incerteza sobre essa informa√ß√£o. Uma cr√≠tica √† abordagem probabil√≠stica √© a dificuldade em saber exatamente a distribui√ß√£o de probabilidade do fen√¥meno. </p>
</li>
</ul>
<hr />
<p><code>üìù</code> <strong>Exemplo (modelo capture-recapture)</strong></p>
<p>Suponha que queremos estimar o n√∫mero de √¥nibus <script type="math/tex">N</script> em uma cidade. Uma forma de fazer isso √© a seguinte: contamos a quantidade vista de √¥nibus em um dia (<script type="math/tex">q_1</script>) e armazenamos a identifica√ß√£o de cada um. No dia seguinte, fazemos a mesma coisa e obtemos (<script type="math/tex">q_2</script>). Seja <script type="math/tex">n</script> o n√∫mero de √¥nibus que vimos nos dois dias. Qual a distribui√ß√£o de <script type="math/tex">n</script>? Olhando para o segundo dia, em uma popula√ß√£o de tamanho <script type="math/tex">N</script>, t√≠nhamos <script type="math/tex">q_1</script> √¥nibus de interesse para recontar. Nossa amostra √© de tamanho <script type="math/tex">q_2</script>. Isso define a <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">distribui√ß√£o hipergeom√©trica</a>, pois a amostragem do segundo dia √© sem reposi√ß√£o (note que simplificamos que s√≥ podemos ver o mesmo √¥nibus uma vez). Logo</p>
<p>
<script type="math/tex; mode=display">n \sim Hypergeometric(N, q_1, q_2).</script>
</p>
<p>Sabemos que <script type="math/tex">\mathbb{E}[n] = (q_1/N) \cdot q_2 \implies \hat{N} = q_1 \cdot q_2 / n</script> √© um poss√≠vel estimador para <script type="math/tex">N</script>. Note que esse estimador n√£o √© necessariamente n√£o enviesado, pois <script type="math/tex">\mathbb{E}[1/n] \neq 1/\mathbb{E}[n]</script>.</p>
<hr />
<ul>
<li>
<p>Para aproximar uma distribui√ß√£o de probabilidade de um fen√¥meno, duas abordagens estat√≠sticas s√£o usadas: <strong>n√£o param√©trica</strong> e <strong>param√©trica</strong>. Na primeira, a estimativa procura assumir o m√≠nimo de hip√≥teses poss√≠vel, procurando uma estima√ß√£o funcional. J√° a segunda vem de uma densidade parametrizada, em que o par√¢metro de dimens√£o finita √© desconhecido.</p>
</li>
<li>
<p>Um modelo estat√≠stico param√©trico consiste de observa√ß√µes de uma vari√°vel aleat√≥ria <script type="math/tex">x \in \mathcal{X}</script> (espa√ßo de estados) com distribui√ß√£o cuja densidade √© <script type="math/tex">f(x | \theta)</script> e <script type="math/tex">\theta \in \Omega</script> (espa√ßo dos par√¢metros) √© desconhecido com dimens√£o finita. </p>
</li>
<li>
<p>Logo, m√©todos estat√≠sticos permitem fazer infer√™ncia sobre <script type="math/tex">\theta</script> a partir de <script type="math/tex">x</script>, enquanto a modelagem probabil√≠stica caracteriza o comportamento de observa√ß√µes futuras condicionadas em <script type="math/tex">\theta</script>. </p>
</li>
</ul>
<h2 id="modelo-parametrico">Modelo param√©trico</h2>
<p>Schervish apresenta uma defini√ß√£o formalizada de modelo param√©trico, a qual eu apresento a seguir. </p>
<blockquote>
<p>Seja <script type="math/tex">(S, \mathcal{A}, \mu)</script> um espa√ßo de probabilidade, e <script type="math/tex">(\mathcal{X}, \mathcal{B})</script> e <script type="math/tex">(\Omega, \tau)</script> espa√ßos de Borel (espa√ßo mensur√°vel isomorfo a um subconjunto mensur√°vel dos reais. Em geral, veremos que esses espa√ßos s√£o subconjuntos mensur√°veis dos reais). Seja <script type="math/tex">X : S \to \mathcal{X}</script> e <script type="math/tex">\Theta : S \to \Omega</script> fun√ß√µes mensur√°veis. Chamamos <script type="math/tex">\Theta</script> de par√¢metro e <script type="math/tex">\Omega</script> de espa√ßo de par√¢metros. A distribui√ß√£o de <script type="math/tex">X | \Theta = \theta</script> √© fam√≠lia param√©trica de distribui√ß√µes de <script type="math/tex">X</script> dada por <script type="math/tex">P_{\theta}</script>. A medida de probabilidade <script type="math/tex">\mu_{\Theta}</script> sobre <script type="math/tex">(\Omega, \tau)</script> induzida por <script type="math/tex">\Theta</script> a partir de <script type="math/tex">\mu</script> √© chamada de distribui√ß√£o a priori (<script type="math/tex">\mu_{\Theta}(B) = \mu(\Theta \in B), B \in \tau</script>). A densidade de <script type="math/tex">P_{\theta}</script> (que √© absolutamente cont√≠nua) com respeito √† uma medida <script type="math/tex">\nu</script> √© dada por
<script type="math/tex; mode=display">f_{X|\Theta}(x|\theta) = \frac{dP_{\theta}}{d\nu}(x),</script>
a derivada de Radon-Nikodym. </p>
</blockquote>
<h2 id="paradigma-bayesiano">Paradigma bayesiano</h2>
<p>No paradigma bayesiano, as quantidades desconhecidas s√£o tratadas como vari√°veis aleat√≥rias, incluindo o par√¢metro <script type="math/tex">\theta</script>. Na p√°gina 12 de seu livro, Shervish apresenta uma justificativa matem√°tica para esse fato. Assim, se temos um modelo <script type="math/tex">P_{\theta}</script> para <script type="math/tex">x</script>, precisamos de uma distribui√ß√£o para <script type="math/tex">\theta</script>, a qual chamamos de <strong>distribui√ß√£o a priori</strong>. Com elas, constru√≠mos uma distribui√ß√£o em <script type="math/tex">\mathcal{X} \times \Omega</script>. Em particular, </p>
<p>
<script type="math/tex; mode=display">\Pr((x,\theta) \in B) = \int_{\Omega} \int_{\mathcal{X}} I_B(u, v) f_{x | \theta}(u|v)f_{\theta}(v) \, du \, dv,</script>
</p>
<p>se <script type="math/tex">f_{\theta}</script> for a densidade da distribui√ß√£o de <script type="math/tex">\theta</script>. Para isso, basta exigir que <script type="math/tex">f_{X | \Theta}</script> seja mensur√°vel em <script type="math/tex">\mathcal{B} \otimes \tau</script>.Matematicamente, probabilidades podem representar cren√ßas numericamente, relacionando informa√ß√£o com probabilidade. A Regra de Bayes prov√™ um m√©todo racional para atualizar essas cren√ßas frente a novas informa√ß√µes. O processo indutivo de atualizar cren√ßas com Bayes √© chamada de infer√™ncia bayesiana. </p>
<h3 id="teorema-de-bayes">Teorema de Bayes</h3>
<p>Se <script type="math/tex">E</script> √© um evento com probabilidade positiva e <script type="math/tex">A</script> √© um outro evento, temos que 
<script type="math/tex; mode=display">\Pr(A | E) = \frac{\Pr(E |A) \Pr(A)}{\Pr(E)}.</script>
Podemos expressar atrav√©s de densidades, com 
<script type="math/tex; mode=display">p(\theta | x) = \frac{f(x|\theta)\pi(\theta)}{\int_{\Omega} f(x|t)\pi(t) \, dt},</script>
em que <script type="math/tex">\pi(\theta)</script> √© a densidade da priori do par√¢metro <script type="math/tex">\theta</script> e <script type="math/tex">p(\theta | x)</script> √© chamada de <strong>distribui√ß√£o a posteriori</strong> de <script type="math/tex">\theta</script> (para uma demonstra√ß√£o detalhada do Teorema de Bayes, vale conferir a p√°gina 16 do livro de Schervish). Al√©m disso, como o par√¢metro <script type="math/tex">\theta</script> √© desconhecido, tamb√©m denotamos a densidade de <script type="math/tex">x</script> condicionada em <script type="math/tex">\theta</script> como uma fun√ß√£o de <script type="math/tex">\theta</script>, ap√≥s observar <script type="math/tex">x</script>. Nesse caso, chamamos de <strong>fun√ß√£o de verossimilhan√ßa</strong> <script type="math/tex">l(\theta | x) = f(x | \theta)</script> para cada <script type="math/tex">\theta \in \Omega</script> e <script type="math/tex">x</script> observado. O denominador da express√£o acima √© chamada de <strong>densidade preditiva a priori</strong> e n√£o depende de <script type="math/tex">\theta</script>. √â a marginal no espa√ßo de estados. </p>
<p>A distribui√ß√£o a priori encapsula a informa√ß√£o dispon√≠vel sobre o par√¢metro <script type="math/tex">\theta</script> antes do experimento, incluindo a incerteza residual. Se a distribui√ß√£o a priori e a distribui√ß√£o dos dados representam cren√ßas racionais, <a href="https://books.google.com.br/books?id=V8jT2SimGR0C&amp;pg=PA2&amp;lpg=PA2&amp;dq=%22Bayes%E2%80%99+rule+is+an+optimal+method%22&amp;source=bl&amp;ots=X6NYVjaGMG&amp;sig=ACfU3U35KV7iPBPmwMc8lNcupnc5zrEysg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiH7PmO0uT2AhWQVt8KHTpsBCgQ6AF6BAgcEAM#v=onepage&amp;q=%22Bayes%E2%80%99%20rule%20is%20an%20optimal%20method%22&amp;f=false">a regra de Bayes √© o m√©todo √≥timo para atualizar essas cren√ßas</a> sobre o par√¢metro dada nova informa√ß√£o. Claro que, em geral, n√£o conseguimos explorar as cren√ßas de modo perfeito e a posteriori n√£o vai ser √≥tima, nesse sentido. </p>
<hr />
<p><code>üìù</code> <strong>Exemplo (Bayes, 1974)</strong></p>
<p>Uma bola de sinuca <script type="math/tex">O</script> √© rolada em uma linha de comprimento 1. √â natural assumir que ela tem uma distribui√ß√£o uniforme de parar em qualquer lugar, s√≥ dependendo da for√ßa exercida sobre ela. Seja <script type="math/tex">p</script> o ponto de parada. Em seguida, rolamos uma outra bola <script type="math/tex">n</script> vezes e contamos a quantidade de vezes (<script type="math/tex">X</script>) que ela parou antes de <script type="math/tex">B</script>. Nesse caso, observado <script type="math/tex">X=x</script>, queremos inferir <script type="math/tex">p</script>. Se <script type="math/tex">p</script> fosse conhecido, qual seria distribui√ß√£o de <script type="math/tex">X</script>? Veja que temos <script type="math/tex">n</script> experimentos independentes e id√™nticos de sucesso ou falha, com probabilidade de sucesso <script type="math/tex">p</script> (lembrando da distribui√ß√£o uniforme!). Nesse caso <script type="math/tex">X|p \sim Bernoulli(n, p)</script>. Com essas configura√ß√µes, podemos verificar que 
<script type="math/tex; mode=display">\Pr(a < p < b | X=x) = \frac{\int_a^b p^x(1-p)^{n-x} \, dp}{B(x+1, n-x+1)},</script>
em que <script type="math/tex">B</script> √© a <a href="https://en.wikipedia.org/wiki/Beta_function">fun√ß√£o Beta</a>.</p>
<hr />
<p>Enquanto a estat√≠stica cl√°ssica √© dirigida por princ√≠pios justificados axiomaticamente, a abordagem bayesiana incorpora esses princ√≠pios sem a restri√ß√£o sobre os procedimentos e tamb√©m rejeita outros princ√≠pios. Por exemplo, o conceito de estimadores n√£o enviesados, em geral preferidos na estat√≠stica cl√°ssica, imp√µe restri√ß√µes fortes sobre os procedimentos adotados e leva a performances ineficientes (ver <a href="https://en.wikipedia.org/wiki/Stein%27s_example">exemplo de Stein</a>). Isso acontece, pois a justificativa √© assint√≥tica, j√° que em m√©dia o estimador √© correto. </p>
<p>Por fim, em estat√≠stica bayesiana, <strong>TODAS AS INFER√äNCIAS S√ÉO BASEADAS NA DISTRIBUI√á√ÉO A POSTERIORI</strong>.</p>
<h2 id="um-pouco-de-historia">Um pouco de hist√≥ria</h2>
<p>Em 1763, √© publicado <a href="https://www.jstor.org/stable/105741?seq=1">An Essay towards Solving a Problem in the Doctrine of Chances</a>, paper atribu√≠do a Thomas Bayes e publicado por Richard Price. O principal objeto desse trabalho, al√©m do exemplo acima, √© o que conhecemos como Teorema de Bayes, mas com a priori sendo uniforme. Laplace, em <a href="https://www.york.ac.uk/depts/maths/histstat/memoir1774.pdf">Memoir on the Probability of the Causes of Events</a> foi quem descreveu em uma forma mais geral, apesar de ainda ser discreta. Do ponto de vista probabil√≠stico, o Teorema de Bayes √© apenas uma forma de mensurar a incerteza. A controv√©rsia adv√©m da interpreta√ß√£o da probabilidade e se ele deveria ser considerado ponto central no processo de aprendizado. </p>
<h2 id="visao-subjetiva-da-probabilidade">Vis√£o subjetiva da probabilidade</h2>
<p>A vis√£o de que o mundo √© determin√≠stico ou n√£o, como a discuss√£o do <a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">Dem√¥nio de Laplace</a>, √© pouco importante na verdade para a estat√≠stica. O que importa √© a incerteza que temos sobre as quantidades. No pref√°cio de seu livro <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119286387.fmatter">Theory of Probability</a>, Bruno de Finetti argumenta que "probabilidade n√£o existe" no sentido <em>objetivo</em>. A √∫nica exig√™ncia √© que exista consist√™ncia em nossas cren√ßas e na rela√ß√£o com dados objetivos. Basicamente, a defini√ß√£o de probabilidade √© subjetiva: a taxa em que o indiv√≠duo est√° disposto a apostar na ocorr√™ncia de um evento.</p>
<p>Considere um dado normal de seis lados. Um frequentista afirmaria que, por simetria, cada lado tem igual chance de ocorrer. Evid√™ncia emp√≠rica passada suportaria sua afirma√ß√£o. Um subjetivista ouviria os argumentos, mas o que realmente iria considerar seria sua cren√ßa sobre o que acontecer√° em uma jogada de dados, isto √©, quanto seria apostado em cada lado, dada a informa√ß√£o presente. Logo, no trabalho de De Finetti, Probabilidade e Pre√ßo s√£o equivalentes. Para uma discuss√£o mais detalhada, consulte <a href="https://faculty.fuqua.duke.edu/~rnau/definettiwasright.pdf">esse trabalho</a>.</p>
<h2 id="principio-da-verossimilhanca-e-principio-da-suficiencia">Princ√≠pio da Verossimilhan√ßa e Princ√≠pio da Sufici√™ncia</h2>
<h3 id="suficiencia">Sufici√™ncia</h3>
<p>Seja <script type="math/tex">x \sim f(x | \theta)</script>. Uma fun√ß√£o/estat√≠stica <script type="math/tex">T: \mathcal{X} \to \mathbb{R}^k</script> (a imagem de <script type="math/tex">T</script>, juntamente com o conjunto de seus singletons, pode ser qualquer espa√ßo mensur√°vel) √© <strong>suficiente</strong> se a distribui√ß√£o de <script type="math/tex">x</script> condicionada em <script type="math/tex">T(x)</script> n√£o depende de <script type="math/tex">\theta</script>. Para mais detalhes, ver <a href="/ta-sessions/infestatistica_BSc/SufficientStatistics/">aqui</a>. De forma simplificada, <script type="math/tex">T(x)</script> traz toda a informa√ß√£o sobre <script type="math/tex">\theta</script> advinda de <script type="math/tex">x</script>. Schervish (p√°gina 84) adiciona o fato de que para qualquer priori <script type="math/tex">\pi(theta)</script>, a distribui√ß√£o a posteriori de <script type="math/tex">\theta</script> condicionada em <script type="math/tex">x</script> e a posteriori condicionada em <script type="math/tex">T(x)</script> s√£o iguais quase certamente. Como demonstrado no Teorema 2.14 do mesmo livro, essas defini√ß√µes s√£o equivalentes dadas algumas hip√≥teses de regularidade.</p>
<p>O <strong>Teorema da fatora√ß√£o Fisher-Neyman</strong> mostra que se a densidade de <script type="math/tex">x</script> √© a derivada de Radon-Nikodym para alguma medida de probabilidade (<script type="math/tex">\sigma</script> - finita) cuja distribui√ß√£o seja absolutamente cont√≠nua, ent√£o vale que <script type="math/tex">T(x)</script> √© suficiente para <script type="math/tex">\theta</script> se, e somente se, existem fun√ß√µes <script type="math/tex">g</script> e <script type="math/tex">h</script> n√£o-negativas tal que </p>
<p>
<script type="math/tex; mode=display">f(x|\theta) = g(T(x)|\theta)h(x|T(x)).</script>
</p>
<p>O conceito de sufici√™ncia foi introduzido por Fisher e est√° associado com o seguinte princ√≠pio:</p>
<blockquote>
<p><strong>Princ√≠pio da Sufici√™ncia (PS):</strong> Se duas observa√ß√µes <script type="math/tex">x</script> e <script type="math/tex">y</script> s√£o tais que <script type="math/tex">T(x) = T(y)</script> para alguma estat√≠stica suficiente <script type="math/tex">T</script>, ent√£o elas devem levar √† mesma infer√™ncia sobre o par√¢metro.</p>
</blockquote>
<hr />
<p><code>üìù</code> <strong>Exemplo</strong></p>
<p>Suponha que observamos <script type="math/tex">x = (x_1, \dots, x_n) \overset{iid}{\sim} Exponential(\lambda)</script>. Uma estat√≠stica suficiente para <script type="math/tex">\lambda</script> √© a m√©dia amostral <script type="math/tex">T(x) = \bar{x}</script>, em particular, 
<script type="math/tex; mode=display">f(x | \lambda) = \lambda^n e^{-\lambda n \bar{x}}.</script>
Logo, infer√™ncias sobre <script type="math/tex">\lambda</script> s√≥ devem se basear em <script type="math/tex">\bar{x}</script>, segundo o Princ√≠pio da sufici√™ncia.</p>
<hr />
<h3 id="principio-da-verossimilhanca">Princ√≠pio da Verossimilhan√ßa</h3>
<p>Esse conceito √© tamb√©m atribu√≠do a <a href="https://www.amazon.com/Statistical-Methods-Scientific-Inference-Ronald/dp/0050008706">Fisher</a>, mas a sua formaliza√ß√£o se deve a <a href="https://www.jstor.org/stable/pdf/2281640.pdf">Birnbaum (1962)</a>.</p>
<blockquote>
<p><strong>Princ√≠pio da Verossimilhan√ßa (PV):</strong> a informa√ß√£o trazida por uma observa√ß√£o <script type="math/tex">x</script> sobre <script type="math/tex">\theta</script> √© inteiramente contida na fun√ß√£o de verossimilhan√ßa <script type="math/tex">l(\theta|x)</script>. Al√©m do mais, se duas observa√ß√µes <script type="math/tex">x</script> e <script type="math/tex">y</script> dependem de <script type="math/tex">\theta</script>, de forma que <script type="math/tex">l_1(\theta|x) = cl_2(\theta|y), \, \forall \theta \in \Omega</script> para alguma constante <script type="math/tex">c</script>, ent√£o elas levam √† mesma infer√™ncia sobre <script type="math/tex">\theta</script>. </p>
</blockquote>
<p>Uma outra forma de expressar esse princ√≠pio √© o seguinte: Se <script type="math/tex">E</script> e <script type="math/tex">E'</script> s√£o experimentos definidos em <script type="math/tex">\Omega</script>, representados pelas densidades <script type="math/tex">f(x, \theta)</script> e <script type="math/tex">g(y, \theta)</script>, e <script type="math/tex">x</script> e <script type="math/tex">y</script> s√£o observa√ß√µes determinando a mesma fun√ß√£o de verossimilhan√ßa, ent√£o a evid√™ncia trazida por ambos os experimentos √© a mesma vista a partir dessas observa√ß√µes, isto √©, o resultado <script type="math/tex">x</script> de qualquer experimento <script type="math/tex">E</script> √© caracterizado somente pela verossimilhan√ßa at√© uma constante. </p>
<hr />
<p><code>üìù</code> <strong>Exemplo</strong></p>
<p>Seja <script type="math/tex">\theta \in [0,1]</script> a propor√ß√£o de doentes em uma popula√ß√£o. Um examinador encontrou nove pessoas saud√°veis e tr√™s doentes. Se nenhuma informa√ß√£o adicional √© obtida, podemos propor dois modelos diferentes para esse fen√¥meno:</p>
<p>(1) O examinador testou 12 pessoas e observou <script type="math/tex">x \sim Binomial(12, \theta)</script> com <script type="math/tex">x = 3</script>.</p>
<p>(2) Ele questionou <script type="math/tex">N = 12</script> pessoas at√© encontrar <script type="math/tex">3</script> doentes. Nesse caso, <script type="math/tex">N \sim NegativeBinomial(3, \theta)</script>
</p>
<p>Apesar do dado ser diferente em ambos os experimentos, as verossimilhan√ßas s√£o proporcionais. Portanto, as infer√™ncias devem ser as mesmas sobre <script type="math/tex">\theta</script>.</p>
<hr />
<p>Como as infer√™ncias s√£o baseadas na posteriori, a abordagem bayesiana satisfaz o Princ√≠pio da Verossimilhan√ßa. Por√©m, na abordagem frequentista, isso n√£o √© verdade, j√° que √© baseada no comportamento m√©dio dos procedimentos. O estimador de m√°xima verossimilhan√ßa tamb√©m satisfaz.</p>
<h3 id="derivando-o-principio-da-verossimilhanca">Derivando o princ√≠pio da verossimilhan√ßa</h3>
<blockquote>
<p><strong>Princ√≠pio da Condicionalidade (PC):</strong> Se dois experimentos <script type="math/tex">E</script> e <script type="math/tex">E'</script> sobre <script type="math/tex">\Omega</script> est√£o dispon√≠veis e um deles √© selecionado com probabilidade <script type="math/tex">p</script>, a infer√™ncia resultante sobre <script type="math/tex">\theta</script> s√≥ deveria depender do experimento selecionado.</p>
</blockquote>
<p>O fato que Birnbaum demonstrou √© que PS + PC = PL. Isso √© interessante, pois, para muitos estat√≠sticos, PS e PC s√£o aceit√°veis, mais PL n√£o. Isso faz com que os resultados cient√≠ficos, para serem coerentes, devessem ser descritos atrav√©s da fun√ß√£o de verossimilhan√ßa, e n√£o por n√≠veis de signific√¢ncia e estimativas intervalares. <a href="https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-7/issue-none/What-does-the-proof-of-Birnbaums-theorem-prove/10.1214/13-EJS857.full">Evans, 2013</a> utiliza teoria dos conjuntos para mostrar que a demonstra√ß√£o de Birnbaum tem falhas, j√° que ignora uma hip√≥tese chave. <a href="https://www.journals.uchicago.edu/doi/abs/10.1093/bjps/axt039?journalCode=bjps">Gandenberger, 2015</a> ofereceu uma nova demonstra√ß√£o para o Princ√≠pio da Verossimilhan√ßa, mas com hip√≥teses diferentes. <a href="https://vicpena.github.io/isba2016.pdf">Aqui</a> temos um breve resumo em formato de slides.</p>
<h2 id="distribuicoes-a-priori-e-a-posteriori">Distribui√ß√µes a priori e a posteriori</h2>
<p>Dada a distribui√ß√£o de <script type="math/tex">x</script> dada por <script type="math/tex">f(x|\theta)</script> e a distribui√ß√£o a priori <script type="math/tex">\pi(\theta)</script>, podemos derivar as seguintes distribui√ß√µes:</p>
<p>(a) a distribui√ß√£o conjunta
<script type="math/tex; mode=display"> \varphi(x, \theta) = f(x |\theta) \pi(\theta);</script>
</p>
<p>(b) a distribui√ß√£o marginal de <script type="math/tex">x</script>
<script type="math/tex; mode=display">m(x) = \int f(x|\theta) \pi(\theta) \, d\theta;</script>
</p>
<p>(c) a distribui√ß√£o a posteriori de <script type="math/tex">\theta</script>
<script type="math/tex; mode=display">p(\theta|x) = \frac{f(x|\theta)\pi(\theta)}{m(x)};</script>
</p>
<p>(d) a distribui√ß√£o preditiva de <script type="math/tex">y</script>, quando <script type="math/tex">y \sim g(y|x, \theta),</script>
<script type="math/tex; mode=display">g(y|x) = \int g(y|\theta, x) \pi(\theta | x) \, d\theta.</script>
</p>
<h3 id="distribuicoes-a-priori-improprias">Distribui√ß√µes a priori impr√≥prias</h3>
<p>Para a especifica√ß√£o de um modelo (param√©trico) segundo o preceito bayesiano, √© preciso definir uma fam√≠lia param√©trica para as observa√ß√µes <script type="math/tex">X</script> e uma distribui√ß√£o a priori para <script type="math/tex">\theta</script>. √â importante destacar que ambas s√£o escolhas que introduzem subjetividade. Para especificar uma priori, traduzimos conhecimento pr√©vio em uma distribui√ß√£o de probabilidade. Nem sempre, temos uma informa√ß√£o suficiente para tal. Uma maneira usual de contornar essa situa√ß√£o √© construir uma sequ√™ncia de distribui√ß√µes no espa√ßo de par√¢metros e tomar <script type="math/tex">\pi</script> como a distribui√ß√£o limite. Todavia, ela poder√° sofrer com a propriedade que 
<script type="math/tex; mode=display"> \int_{\Omega} \pi(\theta) \, d\theta = + \infty.</script>
Nesse caso temos uma <strong>distribui√ß√£o impr√≥pria</strong> ou generalizada. </p>
<hr />
<p><code>üìù</code> <strong>Exemplo</strong></p>
<p>Suponha que tenhamos <script type="math/tex">X \sim Normal(\theta, 1)</script>, em que <script type="math/tex">\theta \in \mathbb{R}</script>. Queremos uma priori normal em <script type="math/tex">\theta</script>, mas n√£o temos muita certeza de sua localiza√ß√£o. Logo, uma vari√¢ncia baixa seria uma p√©ssima escolha. Seja <script type="math/tex">\theta \sim Normal(0, n^2)</script>. Qual a vari√¢ncia que podemos dizer que n√£o √© baixa? Se fizermos <script type="math/tex">n \to +\infty</script>, n√£o teremos mais uma distribui√ß√£o normal.</p>
<hr />
<p>Nesses casos, escolhemos uma medida sobre <script type="math/tex">\Omega</script>, cuja posteriori calculada exista, com respeito a <script type="math/tex">\lambda</script>. Nesse caso, basta verificar se 
<script type="math/tex; mode=display">\int_{\Omega} f_{X|\Theta}(x|t) \, d\lambda(t)</script>
√© finita e positiva. Nesse caso, definimos a posteriori segundo a sua f√≥rmula pelo Teorema de Bayes. Para definir matematicamente, de forma precisa, a distribui√ß√£o impr√≥pria, existem algumas tentativas.</p>
<p>(1) Remover a restri√ß√£o de que a probabilidade do espa√ßo √© 1. </p>
<p>(2) Probabilidades s√£o finitamente aditivas, e n√£o contavelmente aditivas.</p>
<p>Em ambos os casos, muitos resultados de probabilidade falham.</p>
<p>Alguns coment√°rios sobre prioris impr√≥prias destacados por Robert (p√°ginas 27-31):</p>
<ul>
<li>
<p>Muitas vezes, a defini√ß√£o de prioris impr√≥prias s√£o derivadas por m√©todos autom√°ticos, quando tem-se pouca ou nenhuma informa√ß√£o sobre o par√¢metro antes de observar o dado (nenhuma informa√ß√£o √© uma express√£o exagerada sujeita √† cr√≠tica, tamb√©m).</p>
</li>
<li>
<p>Se a posteriori estiver bem definida, e os estimadores resultantes tiverem boa performance, j√° temos uma boa justificativa para usar a priori. </p>
</li>
<li>
<p>Distribui√ß√µes impr√≥prias podem muitas vezes serem vistas como limite de distribui√ß√µes pr√≥prias, isto √©, s√£o casos extremos onde a informa√ß√£o a priori n√£o √© confi√°vel.</p>
</li>
<li>
<p>Essas distribui√ß√µes t√™m justificativas frequentistas, em geral.</p>
</li>
<li>
<p>Prioris impr√≥prias n√£o tem interpreta√ß√£o probabil√≠stica. </p>
</li>
<li>
<p>A posteriori <strong>precisa</strong> ser bem-definida. Computacionalmente, amostrar da posteriori se ela for mal-definida vai levar a problemas de estima√ß√£o. Logo, √© essencial verificar se o denominador √© finito e positivo.</p>
</li>
</ul></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../.."</script>
    
    <script src="../../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
