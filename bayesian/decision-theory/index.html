<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">

    
    <title>Teoria da Decis√£o - Teaching Assistant</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../css/base.min.css" rel="stylesheet">
    <link href="../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../..">Teaching Assistant</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li >
                        <a href="../../alglin/info/">√Ålgebra Linear</a>
                    </li>
                
                
                
                    <li >
                        <a href="../../analisenum/info/">An√°lise Num√©rica</a>
                    </li>
                
                
                
                    <li >
                        <a href="../../curvas/info/">Curvas</a>
                    </li>
                
                
                
                    <li >
                        <a href="../../edo/info/">EDO</a>
                    </li>
                
                
                
                    <li >
                        <a href="../../edp/info/">EDP</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Estat√≠stica <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../infestatistica/info/">Infer√™ncia Estat√≠stica</a>
</li>

                        
                            
<li >
    <a href="../info/">Estat√≠stica Bayesiana</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li>
                        <a href="https://lucasmoschen.github.io">P√°gina Inicial</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#teoria-da-decisao">Teoria da Decis√£o</a></li>
            <li class="second-level"><a href="#funcao-utilidade">Fun√ß√£o utilidade</a></li>
                
                <li class="third-level"><a href="#relacao-entre-utilidade-e-perda">Rela√ß√£o entre utilidade e perda</a></li>
            <li class="second-level"><a href="#maximalidade-e-admissibilidade">Maximalidade e admissibilidade</a></li>
                
                <li class="third-level"><a href="#maximalidade">Maximalidade</a></li>
                <li class="third-level"><a href="#admissibilidade">Admissibilidade</a></li>
            <li class="second-level"><a href="#perdas-classicas">Perdas cl√°ssicas</a></li>
                
                <li class="third-level"><a href="#perda-quadratica">Perda quadr√°tica</a></li>
                <li class="third-level"><a href="#perda-absoluta">Perda absoluta</a></li>
                <li class="third-level"><a href="#perda-0-1">Perda 0-1</a></li>
                <li class="third-level"><a href="#perdas-intrinsecas">Perdas intr√≠nsecas</a></li>
            <li class="second-level"><a href="#links">Links</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="teoria-da-decisao">Teoria da Decis√£o</h1>
<p>Em geral, a estat√≠stica se preocupa em propor uma decis√£o frente a um problema apresentado. 
Nesse caso, a avalia√ß√£o deve estar clara, como, por exemplo, com a descri√ß√£o do procedimento e suas consequ√™ncias. 
A Teoria da Decis√£o entra para axiomatizar a estrutura de avaliar um estimador para algum par√¢metro. 
O crit√©rio para avaliar uma tomada de decis√£o √© usualmente atrav√©s de uma <strong>fun√ß√£o de perda</strong>. 
Alguns estat√≠sticos discordam de us√°-la, justamente porque defini-la para um problema pode levar a resultados inesperados. </p>
<p>Seja <script type="math/tex">\mathcal{D}</script> o espa√ßo das decis√µes (por exemplo, uma estimativa √© uma decis√£o) e <script type="math/tex">\Omega</script> o espa√ßo dos par√¢metros.
Uma fun√ß√£o de perda √© uma fun√ß√£o <script type="math/tex">L : \Omega \times \mathcal{D} \to [0, +\infty]</script> e avalia uma penalidade <script type="math/tex">L(\theta, d)</script> em tomar a decis√£o <script type="math/tex">d</script> com respeito a <script type="math/tex">\theta</script>. 
Quando <script type="math/tex">\mathcal{D} = h(\Omega)</script>, temos que <script type="math/tex">L(\theta, d)</script> mede o erro em obter <script type="math/tex">h(\theta)</script> por <script type="math/tex">d</script>.
Escolher uma fun√ß√£o de perda de maneira a considerar o problema em quest√£o n√£o √© uma tarefa f√°cil. 
A complexidade envolvida em defini-la a partir de conceitos subjetivos leva ao uso de perdas matematicamente trat√°veis, como a perda quadr√°tica ou absoluta, por exemplo.</p>
<p>Ent√£o, em uma infer√™ncia bayesiana, do ponto de vista da Teoria da Decis√£o, os tr√™s fatores principais s√£o: a fam√≠lia param√©trica de distribui√ß√µes das observa√ß√µes, a distribui√ß√£o a priori dos par√¢metros, e a fun√ß√£o de perda associada √†s decis√µes. Inclusive a subjetividade em definir a fun√ß√£o de perda e a priori n√£o pode ser separada, conforme destacado por <a href="https://www.wiley.com/en-us/Making+Decisions%2C+2nd+Edition-p-9780471908081">Lindley (1985)</a>. </p>
<hr />
<p><code>üìù</code> <strong>Exemplo (Fun√ß√£o de perda)</strong></p>
<p>Considere o problema de estimar a <script type="math/tex">\mathbb{E}[x] = \theta</script>, em que <script type="math/tex">x \sim Normal(\theta, \sigma^2)</script>, em que <script type="math/tex">\sigma^2</script> √© conhecido.
Nesse caso, <script type="math/tex">\mathcal{D} = \Omega = \mathbb{R}</script>. 
Uma ideia √© usar a perda da forma 
<script type="math/tex; mode=display">L\left(\frac{\delta - \theta}{\sigma}\right), \delta \in \mathcal{D}, \theta \in \Omega,</script>
em que o m√≠nimo de <script type="math/tex">L</script> √© em 0. Al√©m disso, a divis√£o pelo desvio padr√£o reduz o vi√©s de vari√¢ncia grande, principalmente quando a dimens√£o de <script type="math/tex">\theta</script> aumenta. 
Usualmente <script type="math/tex">L(t) = t^2</script> √© a perda escolhida.</p>
<hr />
<h2 id="funcao-utilidade">Fun√ß√£o utilidade</h2>
<p>Utilidade √© definida como o oposto de perda e √© utilizada quando se pretende ordenar consequ√™ncias de decis√µes. 
Ou seja, a utilidade sumariza os poss√≠veis resultados de uma decis√£o, como, por exemplo, o lucro da empresa.
Seja <script type="math/tex">\mathcal{R}</script> o espa√ßo das recompensas, que assumimos possuir uma ordena√ß√£o total <script type="math/tex">\le</script> de forma que para todo <script type="math/tex">r_1, r_2 \in R</script>, tem-se que <script type="math/tex">r_1 \le r_2</script> ou <script type="math/tex">r_2 \le r_1</script> e <script type="math/tex">r_1 \le r_2</script> com <script type="math/tex">r_2 \le r_3</script> implica <script type="math/tex">r_1 \le r_3</script>. 
A primeira propriedade permite comparar qualquer duas recompensas, enquanto a segunda √© a transitividade e fixa uma no√ß√£o que esperar√≠amos de recompensas.</p>
<p>Agora, vamos estender essa no√ß√£o de ordem para <script type="math/tex">\mathcal{P}</script>, o espa√ßo das distribui√ß√µes de probabilidade em <script type="math/tex">\mathcal{R}</script>.
Assumimos que <script type="math/tex">\le</script> est√° dispon√≠vel em <script type="math/tex">\mathcal{P}</script> e que satisfaz </p>
<p>(H1) ordem total;</p>
<p>(H2) transitividade.</p>
<p>No caso, de certa forma, <script type="math/tex">\mathcal{R} \subseteq \mathcal{P}</script> atrav√©s das distribui√ß√µes de Dirac com massa em um ponto <script type="math/tex">r \in \mathcal{R}</script> espec√≠fico.</p>
<p>Queremos construir uma fun√ß√£o <script type="math/tex">U</script> em <script type="math/tex">\mathcal{R}</script> que chamaremos de <strong>fun√ß√£o de utilidade</strong> atrav√©s da rela√ß√£o <script type="math/tex">\le</script>. 
Atrav√©s da seguinte axiomatiza√ß√£o, conseguimos assegurar tal exist√™ncia.
Observe que se a rela√ß√£o 
<script type="math/tex; mode=display">\mathbb{E}^{P_1}[U(r)] \le \mathbb{E}^{P_2}[U(r)]</script>
for equivalente a <script type="math/tex">P_1 \le P_2</script>, ent√£o conseguimos determinar a exist√™ncia dessa rela√ß√£o em <script type="math/tex">\mathcal{P}</script>, o que d√° uma esp√©cie de rec√≠proca do que queremos encontrar.</p>
<p>Considere o conjunto das distribui√ß√µes definidas em um suporte limitado <script type="math/tex">\mathcal{P}_{B}</script>. 
Uma mistura √© definida como <script type="math/tex">P = \alpha P_1 + (1-\alpha)P_2</script>, em que <script type="math/tex">\alpha \in (0,1)</script>. 
Assumimos que</p>
<p>(H3) Se <script type="math/tex">P_1 \le P_2</script>, temos que <script type="math/tex">\forall P \in \mathcal{P}</script>, <script type="math/tex">\alpha P_1 + (1-\alpha) P \le \alpha P_2 + (1-\alpha) P</script>.</p>
<p>(H4) Se <script type="math/tex">P_1 \le P_2 \le P_3</script>, ent√£o existem <script type="math/tex">\alpha, \beta \in (0,1)</script> de forma que, 
<script type="math/tex; mode=display">\alpha P_1 + (1-\alpha) P_3 \le P_2 \le \beta P_1 + (1-\beta)P_3.</script>
</p>
<p>Note que H4 implica que se <script type="math/tex">r_1 \le r \le r_2</script> com <script type="math/tex">r_1 < r_2</script>, ent√£o existe um √∫nico <script type="math/tex">\alpha \in [0,1]</script> de forma que <script type="math/tex">r = \alpha r_1 + (1-\alpha)r_2</script>. Para demonstrar esse resultado, basta supor a n√£o exist√™ncia e usar um argumento de supremo e √≠nfimo associado √† hip√≥tese de (H4). 
Com esse resultado, dados <script type="math/tex">r_1 < r_2</script>, defina <script type="math/tex">U</script> da seguinte forma:
<script type="math/tex; mode=display">
\begin{cases}
    U(r) = v, &\text{se } r_1 \le r \le r_2 \text{ e } r = vr_2 + (1-v)r_1 \\
    U(r) = -\frac{v}{1-v}, &\text{se } r \le r_1 \text{ e } r_1 = vr_2 + (1-v)r \\
    U(r) = \frac{1}{v}, &\text{se } r_2 \le r \text{ e } r_2 = vr + (1-v)r_1.
\end{cases}
</script>
</p>
<p>Com essa defini√ß√£o, temos que <script type="math/tex">U(r_1) = 1</script> e <script type="math/tex">U(r_2) = 0</script>. 
Al√©m do mais, <script type="math/tex">U</script> preserva rela√ß√£o de ordem e se <script type="math/tex">r = \alpha r_1 + (1-\alpha)r_2</script>, ent√£o teremos que <script type="math/tex">U(r) = \alpha U(r_1) + (1-\alpha) U(r_2)</script>.</p>
<p>Agora, precisamos extender a defini√ß√£o de <script type="math/tex">U</script> para <script type="math/tex">\mathcal{P}_{B}</script>, o que existe uma hip√≥tese adicional. 
Defina 
<script type="math/tex; mode=display">
\alpha(r) = \frac{U(r) - U(r_1)}{U(r_2) - U(r_1)}, \beta = \int_{[r_1, r_2]} \alpha(r) dP(r),
</script>
em que <script type="math/tex">P([r_1, r_2]) = 1</script>. 
Note que <script type="math/tex">\alpha</script> √© obtido a partir das rela√ß√µes do par√°grafo anterior, isto √©, sabemos que para cada <script type="math/tex">r</script>, existe <script type="math/tex">\alpha(r)</script>, de forma que <script type="math/tex">r = \alpha(r) r_1 + (1-\alpha(r))r_2</script> e obtemos <script type="math/tex">\alpha</script> atrav√©s da f√≥rmula <script type="math/tex">U(r) = \alpha(r) U(r_1) + (1-\alpha(r)) U(r_2)</script>.
Al√©m disso <script type="math/tex">\beta</script> indica a probabilidade de selecionarmos <script type="math/tex">r_1</script> quando escolhemos uma loteria <script type="math/tex">r = \alpha(r) r_1 + (1-\alpha(r))r_2</script> segundo a distribui√ß√£o de probabilidade <script type="math/tex">P</script>.
Assumimos que </p>
<p>(H5) P = \beta \delta_{r_2} + (1-\beta) \delta_{r_1}</p>
<p>Com isso, √© poss√≠vel definir a fun√ß√£o de utilidade em <script type="math/tex">\mathcal{P}_B</script>. 
Dos resultados que se seguem, considere o seguinte teorema:</p>
<blockquote>
<p><strong>Teorema:</strong> Sejam <script type="math/tex">P_1, P_2 \in \mathcal{P}_B</script>. Ent√£o <script type="math/tex">P_1 \le P_2</script> se, e somente se, <script type="math/tex">\mathbb{E}^{P_1}[U(r)] \le \mathbb{E}^{P_2}[U(r)]</script>. Al√©m do mais, se outra fun√ß√£o de utilidade <script type="math/tex">U^*</script> satisfaz a rela√ß√£o de equival√™ncia, ent√£o existem constantes <script type="math/tex">a > 0</script> e <script type="math/tex">b</script> de forma que <script type="math/tex">U^*(\cdot) = a U(\cdot) + b</script>.</p>
</blockquote>
<p>Com duas hip√≥teses adicionais, podemos extender esse resultado para <script type="math/tex">\mathcal{P}_E</script> que √© o conjunto das distribui√ß√µes <script type="math/tex">P</script> que tem <script type="math/tex">\mathbb{E}^P[U(r)]</script> finita.</p>
<p>Algumas cr√≠ticas ao formalismo incluem: √© imposs√≠vel que um indiv√≠duo consiga comparar quaisquer duas recompensas. 
Al√©m do mais, a transitividade √© algo forte demais. √Äs vezes, resultados da vida real levam √† n√£o transitividade.
A extens√£o de <script type="math/tex">\mathcal{R}</script> para <script type="math/tex">\mathcal{P}</script> tamb√©m √© bastante problematizada, mas explica um pouco da rela√ß√£o da priori com a escolha da fun√ß√£o de perda, no sentido bayesiano.</p>
<p>Um exemplo interessante √© o <a href="https://en.wikipedia.org/wiki/St._Petersburg_paradox">paradoxo de Saint Petersburg</a> que argumenta que o valor esperado do pr√™mio √© infinito, mas a quantidade que os jogadores recebem √© em geral baixa. 
Uma solu√ß√£o poss√≠vel para esse paradoxo √© mudar a fun√ß√£o de utilidade para uma limitada.</p>
<h3 id="relacao-entre-utilidade-e-perda">Rela√ß√£o entre utilidade e perda</h3>
<p>A Teoria da Decis√£o assume que cada a√ß√£o <script type="math/tex">d \in \mathcal{D}</script> pode ser avaliada e leva a uma recompensa <script type="math/tex">r</script> com utilidade <script type="math/tex">U(r)</script>.
Seja <script type="math/tex">U(\theta, d) = \mathbb{E}_{\theta, d}[U(r)]</script>. 
Temos que <script type="math/tex">U</script> mede uma proximidade entre <script type="math/tex">d</script> e <script type="math/tex">h(\theta)</script>.
Ap√≥s definir a fun√ß√£o de utilidade, fazemos <script type="math/tex">L(\theta, d) = -U(\theta, d) \ge 0</script> como a fun√ß√£o de perda. 
Note que essa desigualdade implica que <script type="math/tex">U</script> √© limitada superiormente por <script type="math/tex">0</script>. </p>
<p>√â claro que <script type="math/tex">\min_d L(\theta, d)</script>, quando <script type="math/tex">\theta</script> √© desconhecido, √© praticamente imposs√≠vel, pois dever√≠amos ter um resultado uniforme em <script type="math/tex">\Omega</script>. Por isso, os <strong>frequentistas</strong> usam a no√ß√£o de <strong>perda m√©dia</strong> ou <strong>risco frequentista</strong>:
<script type="math/tex; mode=display">
R(\theta, \delta) = \mathbb{E}_{\theta}[L(\theta, \delta(x))] = \int_{\mathcal{X}} L(\theta, delta(x)) f(x|\theta) \, dx,
</script>
em que <script type="math/tex">\delta(x)</script> √© a decis√£o baseada em <script type="math/tex">x</script> quando <script type="math/tex">x \sim f(x|\theta)</script>.
Chamamos <script type="math/tex">\delta</script> de <strong>estimador</strong>, enquanto <script type="math/tex">\delta(x)</script> de estimativa. 
No cen√°rio frequentista, estimadores s√£o comparados segundo a performance a longo-prazo, para todos os valores de <script type="math/tex">\theta</script>.</p>
<p>Note que <script type="math/tex">R(\theta, \delta)</script> √© uma perda m√©dia ponderada sobre a distribui√ß√£o de  <script type="math/tex">x</script>. 
Logo, o dado observado n√£o √© considerado nesse caso, o que √© uma cr√≠tica ao m√©todo.
Al√©m disso, existe uma controv√©rsia sobre a ideia de repetir experimentos, conceito importante para o frequentismo. 
Por fim, para cada <script type="math/tex">\delta</script>, temos que <script type="math/tex">R(\cdot, \delta)</script> √© uma fun√ß√£o e, portanto, n√£o induz uma ordem total no conjunto de procedimentos.</p>
<p>No procedimento bayesiano, j√° integramos sobre o espa√ßo de <script type="math/tex">\Omega</script> dos par√¢metros. 
Assim, usamos a <strong>perda esperada a posteriori</strong>:
<script type="math/tex; mode=display">
\varrho(\pi, d \mid x) = \mathbb{E}^{\pi}[L(\theta, d)| x] = \int_{\Omega} L(\theta, d) \pi(\theta \mid x) \, d \theta, 
</script>
em que <script type="math/tex">\pi(\theta \mid x) \propto f(x \mid \theta)\pi(\theta)</script>. 
O <strong>erro integrado</strong> √© definido como 
<script type="math/tex; mode=display">
r(\pi, \delta) = \mathbb{E}^{\pi}[R(\theta, \delta)] = \int_{\Omega} \int_{\mathcal{X}} L(\theta, \delta(x)) f(x|\theta) \, dx \, \pi(\theta) \, d\theta = \int_{\mathcal{X}} \varrho(\pi, \delta(x) | x) m(x) \, dx,
</script>
em que a √∫ltima rela√ß√£o √© uma aplica√ß√£o do Teorema de Fubini dado que <script type="math/tex">L \ge 0</script>.
Al√©m do mais, para minimizar <script type="math/tex">r(\pi, \delta)</script>, para cada <script type="math/tex">x</script>, podemos tomar <script type="math/tex">d = \delta(x)</script> que minimiza <script type="math/tex">\varrho(\pi, d | x)</script>, pela √∫ltima igualdade da express√£o acima.</p>
<blockquote>
<p><strong>Estimador de Bayes:</strong> Seja uma priori <script type="math/tex">\pi</script> e uma perda <script type="math/tex">L</script>. 
O estimador de Bayes √© <script type="math/tex">\delta^{\pi}</script> que minimiza <script type="math/tex">r(\pi, \delta)</script>. 
Em particular, para cada <script type="math/tex">x</script>, temos que <script type="math/tex">\delta^{\pi}(x) = \arg \min_d \varrho(\pi, d | x)</script>. 
O risco bayesiano √© o valor <script type="math/tex">r(\pi) = r(\pi, \delta^{\pi})</script>.</p>
</blockquote>
<p>Note que para perdas estritamente convexas, o estimador de Bayes √© √∫nico.</p>
<h2 id="maximalidade-e-admissibilidade">Maximalidade e admissibilidade</h2>
<p>Considere <script type="math/tex">\mathcal{D}^*</script> o espa√ßo das distribui√ß√µes de probabilidade em <script type="math/tex">\mathcal{D}</script>. 
Um <strong>estimador aleatorizado</strong> <script type="math/tex">\delta^*</script> significa tomar uma decis√£o de acordo com a densidade de probabilidade <script type="math/tex">\delta^*(x, \cdot)</script>. 
A perda √© definida como 
<script type="math/tex; mode=display">
L(\theta, \delta^*(x)) = \int_{\mathcal{D}} L(\theta, a) \delta^*(x, a) \, da.
</script>
Usar esse estimador n√£o √© usual porque ele adiciona ru√≠do em um fen√¥meno para tomar uma decis√£o sob incerteza.
Al√©m do mais, ele n√£o obedece o Princ√≠pio da Verossimilhan√ßa, dado que para o mesmo valor de <script type="math/tex">x</script>, podem existir v√°rios valores estimados.</p>
<hr />
<p><code>üìù</code> <strong>Exemplo (Estimador randomizado)</strong></p>
<p>Podemos definir um estimador randomizado segundo
<script type="math/tex; mode=display">
\delta^*(x_1, x_2)(t) = \begin{cases}
    1_{2t = x_1 + x_2} &\text{se } x_1 \neq x_2  \\
    [1_{t = x_1 - 1} + 1_{t = x_1 + 1}]/2 &\text{se } x_1 = x_2,
\end{cases}
</script>
em que <script type="math/tex">1_{v}</script> √© a massa de Dirac em <script type="math/tex">v</script>. </p>
<hr />
<p>Para toda priori <script type="math/tex">\pi</script>, o risco de Bayes √© o mesmo no conjunto dos estimadores randomizados e n√£o randomizados, isto √©, 
<script type="math/tex; mode=display">
\inf_{\delta \in \mathcal{D}} r(\pi, \delta) = \inf_{\delta^* \in \mathcal{D}^*} r(\pi, \delta^*) = r(\pi).
</script>
Como um procedimento randomizado √© a m√©dia de riscos de estimadores n√£o randomizados, ele n√£o pode melhor√°-los.</p>
<h3 id="maximalidade">Maximalidade</h3>
<blockquote>
<p><strong>Risco minimax</strong>: <script type="math/tex">\bar{R} = \inf_{\delta \in \mathcal{D}^*} \sup_{\theta} R(\theta, \delta) = \inf_{\delta \in \mathcal{D}^*} \sup_{\theta} \mathbb{E}_{\theta}[L(\theta, \delta(x))]</script>. 
Um estimador minimax √© um estimador <script type="math/tex">\delta_0</script> que satisfaz <script type="math/tex">\sup_{\theta} R(\theta, \delta_0) = \bar{R}</script>. </p>
</blockquote>
<p>Note que esse estimador, toma o pior caso para <script type="math/tex">\theta</script> e ent√£o minimiza para os procedimentos desse pior caso. 
Esse m√©todo enxerga a natureza como um agente inimigo que tende a escolher o pior caso.</p>
<p>O estimador minimax nem sempre existe. 
Para isso, condi√ß√µes suficientes precisam ser estudadas.
Se <script type="math/tex">\Omega</script> √© finito e <script type="math/tex">L</script> √© cont√≠nua, ent√£o existe uma estrat√©gia minimax.
Outra proposta √© verificar que o conjunto das fun√ß√µes de risco em <script type="math/tex">\mathcal{D}</script> √© compacto em um espa√ßo maior em que <script type="math/tex">\mathcal{D}</script> est√° inserido e que a perda √© constante.</p>
<p><strong>Teorema:</strong> Se <script type="math/tex">\mathcal{D} \subseteq \mathbb{R}^k</script> √© um conjunto convexo compacto e <script type="math/tex">L(\theta, d)</script> √© cont√≠nua e convexa como fun√ß√£o de <script type="math/tex">d</script> para <script type="math/tex">\theta</script> fixado, ent√£o existe um estimador minimax n√£o randomizado. 
O estimador ser√° n√£o randomizado pela <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">desigualdade de Jensen</a>. 
Esse resultado √© um caso particular do <em>Teorema Rao-Blackwell</em>.</p>
<p>O <em>risco de Bayes</em> √© sempre menor do que o <em>risco minimax</em>, o que √© expresso matematicamente por 
<script type="math/tex; mode=display">
\underbar{R} = \sup_{\pi} r(\pi) = \sup_{\pi} \inf_{\delta \in \mathcal{D}} r(\pi, \delta) \le \bar{R} = \inf_{d \in \mathcal{D}^*} \sup_{\theta} R(\theta, \delta).
</script>
A <strong>distribui√ß√£o menos favor√°vel</strong> √© <script type="math/tex">\pi^*</script> tal que <script type="math/tex">r(\pi^*) = \underbar{R}</script>. 
O problema de estima√ß√£o tem um <em>valor</em> quando <script type="math/tex">\underbar{R} = \bar{R}</script>.</p>
<p>Um resultado interessante √© que se <script type="math/tex">\delta</script> √© estimador de Bayes com respeito a <script type="math/tex">\pi</script> e <script type="math/tex">R(\theta, \delta) \le r(\pi)</script> para todo <script type="math/tex">\theta \in \Omega</script>, ent√£o <script type="math/tex">\delta</script> √© estimador minimax e <script type="math/tex">\pi</script> √© a distribui√ß√£o menos favor√°vel.</p>
<blockquote>
<p><strong>Teorema:</strong> Considere um problema estat√≠stico que possua um valor, uma distribui√ß√£o menos favor√°vel <script type="math/tex">\pi_0</script> e um estimador minimax <script type="math/tex">\delta^{\pi_0}</script>. 
Ent√£o se <script type="math/tex">\Omega \subseteq \mathbb{R}</script> √© compacto e <script type="math/tex">R(\theta, \delta^{\pi_0})</script> √© fun√ß√£o anal√≠tica de <script type="math/tex">\theta</script>, ent√£o <script type="math/tex">\pi_0</script> tem suporte finito ou <script type="math/tex">R(\theta, \delta^{\pi_0})</script> √© constante.</p>
</blockquote>
<p>Esse teorema mostra que o minimax n√£o √© um bom estimador do ponto de vista bayesiano, dado que (1) ele pode ser randomizado ou (2) ele pode levar a prioris n√£o real√≠sticas com suporte finito.</p>
<h3 id="admissibilidade">Admissibilidade</h3>
<blockquote>
<p><strong>Admissibilidade:</strong> Um estimador <script type="math/tex">\delta_0</script> √© inadmiss√≠vel se existe um estimador <script type="math/tex">\delta_1</script> que domina <script type="math/tex">\delta_0</script>, isto √©, <script type="math/tex">R(\theta, \delta_0) \ge R(\theta, \delta_1)</script> para todo <script type="math/tex">\theta \in \Omega</script>, e pelo menos para um valor <script type="math/tex">\theta_0</script>, vale a desigualdade estrita. 
Caso contr√°rio, o estimador √© admiss√≠vel.</p>
</blockquote>
<p>Construir um estimador apenas considerando a admissibilidade n√£o √© uma boa estrat√©gia, afinal <script type="math/tex">\delta(x) = \theta_0 \in \Omega</script> √© um estimador que tem valor exato para <script type="math/tex">\theta = \theta_0</script>.
Logo, faz sentido considerar maximalidade simultaneamente. 
O interessante √© que se existe um √∫nico estimador minimax, ent√£o ele √© admiss√≠vel. 
A rec√≠proca √© falsa em geral, mas se <script type="math/tex">\delta_0</script> √© admiss√≠vel com risco constante, ent√£o ele √© o √∫nico estimador minimax.</p>
<p>A rela√ß√£o de admissibilidade com estimadores de Bayes √© bem estrita: </p>
<p>(1) Se a priori <script type="math/tex">\pi</script> √© estritamente positiva em <script type="math/tex">\Omega</script>, com risco de Bayes finito, e a fun√ß√£o de risco √© cont√≠nua em <script type="math/tex">\theta</script> para todo <script type="math/tex">\delta</script>, ent√£o o estimador de Bayes <script type="math/tex">\delta^{\pi}</script> √© admiss√≠vel.</p>
<p>(2) Se o estimador de Bayes <script type="math/tex">\delta^{\pi}</script> √© √∫nico, ent√£o ele √© admiss√≠vel.</p>
<h2 id="perdas-classicas">Perdas cl√°ssicas</h2>
<p>Essas perdas s√£o trat√°veis matematicamente e bem documentadas, mesmo que n√£o representem perfeitamente o problema em quest√£o. </p>
<h3 id="perda-quadratica">Perda quadr√°tica</h3>
<p>√â definida como <script type="math/tex">L(\theta, d) = (\theta - d)^2</script>. 
Provavelmente a perda mais utilizada.
Penalizada fortemente desvios altos.
Mas, como a perda √© convexa e vale a desigualdade de Jensen mencionada mais acima, o que exclui estimadores randomizados.
O interessante √© que, sob essa perda, o estimador de Bayes √© a m√©dia a posteriori, um dos valores que pensar√≠amos naturalmente, mesmo sem adicionar a carga da teoria da decis√£o.</p>
<p><strong>Proposi√ß√£o:</strong> O estimador de Bayes <script type="math/tex">\delta^{\pi}</script> associado com a perda quadr√°tica <script type="math/tex">L</script> √© a esperan√ßa a posteriori <script type="math/tex">\delta^{\pi}(x) = \mathbb{E}^{\pi}[\theta | x]</script>. 
O resultado imediato ocorre quando <script type="math/tex">L(\theta, \delta) = w(\theta)(\theta - \delta)^2</script>, como uma pondera√ß√£o. 
Nesse caso, o estimador de Bayes √© 
<script type="math/tex; mode=display">\delta^{\pi}(x) = \frac{\mathbb{E}^{\pi}[w(\theta) \theta | x]}{\mathbb{E}^{\pi}[w(\theta)| x]}.</script>
</p>
<h3 id="perda-absoluta">Perda absoluta</h3>
<p>Uma alternativa √† perda quadr√°tica √© <script type="math/tex">L(\theta, d) = |\theta - d|</script>, que pode ser generalizada para 
<script type="math/tex; mode=display">
L_{k_1, k_2}(\theta, \delta) = \begin{cases}
k_2(\theta - d) &\text{se } \theta > d \\
k_1(d - \theta) &\text{c.c.}
\end{cases}
</script>
A penaliza√ß√£o para desvios maiores √© menor, apesar de manter a convexidade.
√© poss√≠vel tamb√©m propor uma perda como uma mistura dessas perdas. 
Em uma regi√£o pr√≥xima de zero, usamos a perda quadr√°tica. Depois, usamos a perda absoluta.
Com essa perda, por exemplo, n√£o existe estimador de Bayes em forma fechada.</p>
<p>O estimador de Bayes associado a <script type="math/tex">L_{k_1, k_2}(\theta, \delta)</script> e a <script type="math/tex">\pi</script> √© um quartil <script type="math/tex">k_2/(k_1 + k_2)</script> de <script type="math/tex">\pi(\theta | x)</script>. Em particular, quando <script type="math/tex">k_1 = k_2</script>, o estimador √© a mediana a posteriori.</p>
<h3 id="perda-0-1">Perda 0-1</h3>
<p>Essa perda √© mais utilizada no contexto de teste de hip√≥teses. Ela √© definida como <script type="math/tex">L(\theta, \delta) = 1 - 1_{\theta = \delta}</script>.</p>
<hr />
<p><code>üìù</code> <strong>Exemplo (Teste de hip√≥teses)</strong></p>
<p>Seja o teste de hip√≥teses <script type="math/tex">H_0 : \theta \in \Omega_0</script> e <script type="math/tex">H_1 : \theta \in \Omega_1</script>. 
Ent√£o <script type="math/tex">\mathcal{D} = \{0, 1\}</script> em que <script type="math/tex">0</script> significa rejeitar <script type="math/tex">H_0</script>.
Logo queremos estimar a fun√ß√£o <script type="math/tex">1_{\theta \in \Omega_0}</script>. 
O risco frequentista √© 
<script type="math/tex; mode=display">
R(\theta, \delta) = \begin{cases}
    \Pr_{\theta}(\delta(x) = 0), &\text{se } \theta \in \Omega_0 \\
    \Pr_{\theta}(\delta(x) = 1), &\text{c.c.,}
\end{cases}
</script>
que s√£o os erros do tipo 1 e do tipo 2, respectivamente.</p>
<hr />
<p>O estimador de Bayes √© dado por 
<script type="math/tex; mode=display">
\delta^{\pi}(x) = \begin{cases}
    1 &\text{se }\Pr(\theta \in \Omega_0 | x) > \Pr(\theta \in \Omega_1 | x) \\
    0, &\text{c.c.}
\end{cases}
</script>
</p>
<h3 id="perdas-intrinsecas">Perdas intr√≠nsecas</h3>
<p>√Äs vezes, estamos em uma situa√ß√£o n√£o informativa sobre a parametriza√ß√£o natural e a escolha da fun√ß√£o de perda.
O estimador de Bayes n√£o √© invariante por transforma√ß√µes biun√≠vocas em geral.
Dessa forma, pode ser interessante obter perdas invariantes.
Nesse caso, comparar <script type="math/tex">f(\cdot | \delta)</script> com <script type="math/tex">f(\cdot | \theta)</script> pode ser interessante, isto √©, definir 
<script type="math/tex; mode=display">
L(\theta, \delta) = d(f(\cdot | \theta), f(\cdot | \delta)).
</script>
Duas dist√¢ncias usuais s√£o: (1) entropia, Kullback‚ÄìLeibler divergence, ou (2) Hellinger. Elas resultam nas seguintes perdas:</p>
<p>
<script type="math/tex; mode=display">
(1) L_e(\theta, \delta) = \mathbb{E}_{\theta}\left[\log\left(\frac{f(x|\theta)}{f(x|\delta)}\right)\right].
</script>
</p>
<p>
<script type="math/tex; mode=display">
(2) L_H(\theta, \delta) = \frac{1}{2}\mathbb{E}_{\theta}\left[\left(\sqrt{\frac{f(x|\delta)}{f(x|\theta)}} - 1\right)^2\right].
</script>
</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://onlinelibrary.wiley.com/doi/book/10.1002/0471729000">Optimal Statistical Decisions, Morris DeGroot</a>: esse livro expande os resultados de teoria da decis√£o apresentados no livro do Robert.</li>
</ul></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../.."</script>
    
    <script src="../../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
