<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../../img/favicon.ico">

    
    <title>Estatística suficiente - Teaching Assistance</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../../css/base.min.css" rel="stylesheet">
    <link href="../../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../../..">Teaching Assistance</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Graduação <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../alglin/info/">Álgebra Linear</a>
</li>

                        
                            
<li >
    <a href="../../../analisenum/info/">Análise Numérica</a>
</li>

                        
                            
<li >
    <a href="../../../curvas/info/">Curvas</a>
</li>

                        
                            
<li >
    <a href="../../../edo/info/">Equações Diferenciais Ordinárias</a>
</li>

                        
                            
<li >
    <a href="../../../edp/info/">Equações Diferenciais Parciais</a>
</li>

                        
                            
<li >
    <a href="../../../infestatistica_BSc/info/">Inferência Estatística</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Pós-graduação <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../functional_analysis/info/">Análise Funcional</a>
</li>

                        
                            
<li >
    <a href="../../../bayesian/info/">Estatística Bayesiana</a>
</li>

                        
                            
<li >
    <a href="../../../edp_PhD/info/">Equações Diferenciais Parciais e Aplicações</a>
</li>

                        
                            
<li >
    <a href="../../info/">Inferência Estatística</a>
</li>

                        
                            
<li >
    <a href="../../../probability/info/">Probabilidade</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li>
                        <a href="https://lucasmoschen.github.io">Página Inicial</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#estatistica-suficiente">Estatística suficiente</a></li>
            <li class="second-level"><a href="#fatorizacao-de-fisher-neyman">Fatorização de Fisher-Neyman</a></li>
                
            <li class="second-level"><a href="#estatistica-suficiente-minima-e-completa">Estatística suficiente mínima e completa</a></li>
                
            <li class="second-level"><a href="#ancilaridade">Ancilaridade</a></li>
                
            <li class="second-level"><a href="#computacional">Computacional</a></li>
                
                <li class="third-level"><a href="#amostrando">Amostrando!</a></li>
                <li class="third-level"><a href="#ancilaridade_1">Ancilaridade</a></li>
        <li class="first-level "><a href="#estamos-tomando-o-maximo-de-cada-linha-de-x-e-obtendo-100000-amostras-para-x">Estamos tomando o máximo de cada linha de X e obtendo 100000 amostras para X.</a></li>
            <li class="second-level"><a href="#estimadores-aleatorios-e-convexidade">Estimadores aleatórios e convexidade</a></li>
                
                <li class="third-level"><a href="#teorema-de-rao-blackwell">Teorema de Rao-Blackwell</a></li>
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="estatistica-suficiente">Estatística suficiente</h1>
<p>Um estatístico usa a informação de uma amostra <script type="math/tex">X_1, \dots, X_n</script> para fazer inferência sobre uma quantidade de interesse <script type="math/tex">\theta</script>.
De acordo com Fisher, em "On the Mathematical Foundations of Theoretical Statistics", "o objeto dos métodos estatísticos é a redução dos dados".
Como a quantidade de dados é incapaz de ser compreendida diretamente pelo cérebro, ela é reduzida por poucas quantidades que representam o todo, pelo menos a informação relevante para o problema. 
Nesse sentido, uma estatística é uma forma de representar esses dados, em geral diminuir sua dimensão (os próprios dados formam uma estatística, então isso não é uma condição necessária).
De forma precisa, a definição de <strong>estatística</strong> é:</p>
<blockquote>
<p>Seja <script type="math/tex">(\mathcal{T}, \mathcal{C})</script> um espaço mensurável em que <script type="math/tex">\mathcal{C}</script> contenha todos os conjuntos unitários formados pelo elementos de <script type="math/tex">\mathcal{T}</script>. Se <script type="math/tex">T : \mathcal{X} \to \mathcal{T}</script> é mensurável, então <script type="math/tex">T</script> é uma estatística.</p>
</blockquote>
<p>Com isso, podemos definir uma <strong>estatística suficiente</strong> no sentido clássico (lembrando que temos uma contrapartida bayesiana baseada na posteriori).</p>
<blockquote>
<p>Seja <script type="math/tex">T: \mathcal{X} \to \mathcal{T}</script> uma estatística e <script type="math/tex">\mathcal{P}</script> uma família de distribuições parametrizada por <script type="math/tex">\theta</script> e definida em <script type="math/tex">(\mathcal{X}, \mathcal{B})</script> (espaço amostral com <script type="math/tex">\sigma</script>-álgebra <script type="math/tex">\mathcal{B}</script>). Suponha que existem <script type="math/tex">P_{\theta}(\cdot|T)</script> e uma função <script type="math/tex">r : \mathcal{B} \times \mathcal{T} \to [0,1]</script> tal que <script type="math/tex">r(\cdot, t)</script> é uma medida de probabilidade em <script type="math/tex">(\mathcal{X}, \mathcal{B})</script> para todo <script type="math/tex">t \in \mathcal{T}</script>, <script type="math/tex">r(A, \cdot)</script> é mensurável para todo <script type="math/tex">A \in \mathcal{B}</script> e, para todo <script type="math/tex">\theta \in \Theta</script> e <script type="math/tex">B \in \mathcal{B}</script>,
<script type="math/tex; mode=display">
P_{\theta}(B|T=t) = r(B,t)
</script>
quase certamente. Então dizemos que <script type="math/tex">T</script> é <strong>estatística suficiente</strong> para <script type="math/tex">\theta</script>.</p>
</blockquote>
<p>Apesar dessa definição ser bastante complexa, a ideia é que a distribuição condicional de <script type="math/tex">X</script> dado <script type="math/tex">T=t</script> não depende de <script type="math/tex">\theta</script>, isto é, a informação trazida por <script type="math/tex">T=t</script> sobre <script type="math/tex">\theta</script> compreende toda a informação disponível de <script type="math/tex">X</script>.
Após observar <script type="math/tex">T(x) = t</script>, podemos amostrar de <script type="math/tex">r(\cdot, t)</script> e teremos dados falsos que imitam os iniciais, pois a distribuição será a mesma.
Assim, se considerarmos dois experimentadores, um tendo a amostra inteira, e o outro tendo apenas uma estatística suficiente, ambos terão a mesma quantidade de informação sobre o parâmetro de interesse <script type="math/tex">\theta</script>.</p>
<p>Note que, pela lei da esperança total,
<script type="math/tex; mode=display">
P_{\theta}(X \in B) = \mathbb{E}_{\theta}[P_{\theta}(X \in B|T)] = \mathbb{E}_{\theta}[r(B, T)].
</script>
Se tomarmos <script type="math/tex">Y \sim r(\cdot, t)</script> quando <script type="math/tex">T=t</script>, teremos 
<script type="math/tex; mode=display">
P_{\theta}(Y \in B) = \mathbb{E}_{\theta}[P_{\theta}(Y \in B|T)] = \mathbb{E}_{\theta}[r(B, T)].
</script>
</p>
<p><strong>Proposição:</strong> A estatística de ordem <script type="math/tex">(X_{(1)}, \dots, X_{(n)})</script> é estatística suficiente.</p>
<h2 id="fatorizacao-de-fisher-neyman">Fatorização de Fisher-Neyman</h2>
<p>Seja <script type="math/tex">f(\boldsymbol{x}|\theta)</script> a densidade de uma distribuição de <script type="math/tex">\boldsymbol{X} = (X_1, \dots, X_n)</script> (com respeito a uma medida <script type="math/tex">\nu</script>
<script type="math/tex">\sigma</script>-finita, como a medida de Lebesgue em <script type="math/tex">\mathbb{R}^n</script>). Então <script type="math/tex">T(\boldsymbol{X})</script> é estatística suficiente para <script type="math/tex">\theta</script> se, e somente se, existem funções <script type="math/tex">m_1</script> e <script type="math/tex">m_2</script> tal que 
<script type="math/tex; mode=display">
f(\boldsymbol{x}|\theta) = m_1(\boldsymbol{x})m_2(T(\boldsymbol{x}) , \theta), \forall \theta \in \Theta.
</script>
</p>
<p>O lema 2.24 demonstrado no livro de Schervish determina que sob as hipóteses do teorema de Fisher-Neyman e assumindo que <script type="math/tex">T</script> é suficiente, obtemos que existe uma medida em <script type="math/tex">(\mathcal{T}, \mathcal{C})</script> que domina a distribuição de probabilidade de <script type="math/tex">T</script> e define a densidade de <script type="math/tex">T=t</script> sob o parâmetro <script type="math/tex">\theta</script> como <script type="math/tex">m_2(t,\theta)</script>.</p>
<h2 id="estatistica-suficiente-minima-e-completa">Estatística suficiente mínima e completa</h2>
<p>A estatística de ordem é uma estatística que pouco reduz a informação do dado. 
De fato, só retira a questão da ordenação. 
Todavia, algumas vezes uma estatística mais simples também é suficiente e, por isso, faz sentido definir quando ela é mínima.</p>
<blockquote>
<p>Uma estatística suficiente <script type="math/tex">T</script> é dita <strong>suficiente mínima</strong> se para toda estatística suficiente <script type="math/tex">U</script>, existe uma função mensurável <script type="math/tex">g</script> tal que <script type="math/tex">T = g(U)</script> para todo <script type="math/tex">\theta</script>.</p>
</blockquote>
<p><strong>Teorema (Lehmann-Scheffé):</strong> Seja <script type="math/tex">f(x|\theta)</script> a densidade e <script type="math/tex">T</script> uma função mensurável tal que <script type="math/tex">T(x) = T(y) \iff y \in D(x)</script>, com
<script type="math/tex; mode=display">
D(x) = \{y \in \mathcal{X} : f(y|\theta) = f(x|\theta)h(x,y), \forall \theta \text{ e alguma função } h(x,y) \},
</script>
então <script type="math/tex">T(X)</script> é estatística suficiente mínima.</p>
<hr />
<p><code>📝</code> <strong>Exemplo</strong>
}
Seja <script type="math/tex">X_1, \dots, X_n \overset{iid}{\sim} \operatorname{Bernoulli}(\theta)</script>. Temos que 
<script type="math/tex; mode=display">
f(x_1,\dots,x_n|\theta) = \theta^{S_x}(1-\theta)^{n-S_x},
</script>
em que <script type="math/tex">S_x = \sum_{i=1}^n x_i</script>. 
Assim
<script type="math/tex; mode=display">
\frac{f(x_1,\dots,x_n|\theta)}{f(y_1,\dots,y_n|\theta)} = \left(\frac{\theta}{1-\theta}\right)^{S_x-S_y},
</script>
que independe de <script type="math/tex">\theta</script> se, e somente se, <script type="math/tex">S_x = S_y</script>. 
Isso mostra que <script type="math/tex">T(x) = S_x</script> é estatística suficiente mínima.</p>
<hr />
<hr />
<p><code>📝</code> <strong>Exemplo - Família Exponencial</strong></p>
<p>Considere uma distribuição com densidade 
<script type="math/tex; mode=display">
p_{\theta}(x) = \exp\{\eta(\theta)\cdot T(x) - B(\theta)\}h(x)
</script>
com respeito a medida de Lebesgue. 
Pelo Teorema da Fatorização <script type="math/tex">T(x)</script> é estatística suficiente.
Assim
<script type="math/tex; mode=display">
\log\left(\frac{p_{\theta}(y)}{p_{\theta}(x)}\right) = \eta(\theta)\cdot (T(y) - T(x)) + \log(h(y)) - \log(h(x)).
</script>
Logo <script type="math/tex">T</script> é estatística suficiente mínima se, e somente se, o complemento ortogonal de <script type="math/tex">\eta(\theta)</script> possui apenas o <script type="math/tex">0</script>.</p>
<hr />
<blockquote>
<p>Uma estatística <script type="math/tex">T</script> é dita <strong>completa</strong> se para toda função <script type="math/tex">g</script> mensurável e <script type="math/tex">\theta \in \Theta</script>, <script type="math/tex">\mathbb{E}_{\theta}[g(T)] = 0</script> implique <script type="math/tex">g(T) = 0</script>. Ela será <strong>completa limitada</strong> se adicionamos a condição de que <script type="math/tex">g</script> é limitada.</p>
</blockquote>
<p><strong>Teorema de Bahadur:</strong> Se <script type="math/tex">U</script> é uma estatística suficiente completa limitada e de dimensão finita, então ela é suficiente mínima.</p>
<p>Ideias da demonstração:</p>
<ul>
<li>Tome uma outra estatística <script type="math/tex">T</script> e defina <script type="math/tex">V_i(U) = (1 + \exp\{U_i\})^{-1}</script> para cada componente de <script type="math/tex">U</script>. Note que <script type="math/tex">V</script> é limitada.</li>
<li>Defina <script type="math/tex">H_i(t)</script> como o valor esperado de <script type="math/tex">V_i</script> dado que <script type="math/tex">T=t</script> e <script type="math/tex">L_i(u)</script> como o valor esperado de  <script type="math/tex">H_i(T)</script> quando <script type="math/tex">U=u</script>, que não dependem de <script type="math/tex">\theta</script>, pois as estatísticas são suficientes.</li>
<li>Veja que <script type="math/tex">\mathbb{E}_{\theta}[V_i(U) - L_i(U)] = 0</script>, o que implica que <script type="math/tex">\mathbb{P}(V_i = L_i) = 1</script> pois <script type="math/tex">U</script> é completa.</li>
<li>Conclua usando a Lei da Variância Total que <script type="math/tex">U_i = V_i^{-1}(H_i(T))</script>.</li>
</ul>
<p>Note que se <script type="math/tex">U</script> é completa, então <script type="math/tex">U</script> é completa limitada, o que nos dá um resultado mais claro: Uma estatística suficiente e completa é suficiente mínima.</p>
<h2 id="ancilaridade">Ancilaridade</h2>
<p>Na outra ponta, temos estatísticas que são independentes do parâmetro.</p>
<blockquote>
<p>Uma estatística <script type="math/tex">U</script> é dita anciliar se a sua distribuição independe de <script type="math/tex">\theta</script>.</p>
</blockquote>
<hr />
<p><code>📝</code> <strong>Exemplo - Caso normal</strong></p>
<p>Sejam <script type="math/tex">X_1, X_2 \overset{iid}{\sim} \operatorname{Normal}(\mu, 1)</script> e defina <script type="math/tex">U = X_2 - X_1</script>. Soma de normais independentes faz com que 
<script type="math/tex">U \sim \operatorname{Normal}(0, 2)</script> e <script type="math/tex">U</script> é anciliar.</p>
<hr />
<p>Se <script type="math/tex">T=(T_1, T_2)</script> é estatística suficiente mínima e <script type="math/tex">T_2</script> é anciliar, dizemos que <script type="math/tex">T_1</script> é <strong>suficiente condicionalmente</strong> dado <script type="math/tex">T_2</script>.</p>
<p>Quando uma estatística é anciliar, não significa que ela não tem importância e, portanto, deveria ser ignorada. 
Significa que se ela fosse a única observação possível, não mudaríamos a informação sobre <script type="math/tex">\theta</script>. 
Podemos, todavia, alterar a informação sobre outras quantidades, todavia.</p>
<p>Uma estatística ancilar <script type="math/tex">U</script> é <strong>maximal</strong> se toda outra estatística ancilar é função de <script type="math/tex">U</script>.</p>
<p><strong>Teorema de Basu:</strong> se <script type="math/tex">T</script> é uma estatística suficiente completa limitada e <script type="math/tex">U</script> é anciliar, então <script type="math/tex">U</script> e <script type="math/tex">T</script> são independentes sob <script type="math/tex">P_{\theta}</script> para qualquer <script type="math/tex">\theta</script>.</p>
<h2 id="computacional">Computacional</h2>
<p>Nesse notebook, que está disponível <a href="https://nbviewer.org/github/lucasmoschen/ta-sessions/blob/master/Statistical_Inference_MSc/Notebooks/Sufficient_Statistics.ipynb">neste link</a>, faremos alguns poucos experimentos para ilustrar fatos verificados no capítulo de Estatística Suficiente.</p>
<p><code>python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from tqdm import tqdm</code></p>
<h3 id="amostrando">Amostrando!</h3>
<p>Seja <script type="math/tex">X_1, \dots, X_n</script> uma amostra aleatória de uma distribuição <script type="math/tex">P_{\theta}</script>. 
Seja <script type="math/tex">T(X)</script> uma estatística suficiente. 
Sabemos que <script type="math/tex">\mathbb{P}(X_1, \dots, X_n | T(X) = t)</script> independe de <script type="math/tex">\theta</script>.
Suponha então que temos dois experimentadores. 
O primeiro captura todas as amostras e passa para o segundo experimentador apenas o valor de <script type="math/tex">T(X)</script> para economizar!
Vamos verificar que o segundo experimentador consegue, agora, obter amostras fake da amostra original.</p>
<p>Vamos começar com um exemplo simples: <script type="math/tex">X_1, \dots, X_n \sim \operatorname{Normal}(\mu, 1)</script>. Uma estatística suficiente (mínima, inclusive) nesse caso é <script type="math/tex">\bar{X} = n^{-1}(X_1 + \dots + X_n)</script>.</p>
<p>Sabemos que <script type="math/tex">\bar{X} \sim \operatorname{Normal}(\mu, n^{-1})</script>. Assim, 
<script type="math/tex; mode=display">
f(X_1, \dots, X_n | \bar{X} = t) = \frac{(2\pi)^{-n/2}\exp\{-1/2 \sum_{i=1}^n(x_i-\mu)^2\}}{(2\pi n^{-1})^{-1/2}\exp\{-n/2(t-\mu)^2\}} \propto \exp\left\{-\frac{1}{2}(S_x^2 - 2\mu n t + n\mu^2 - nt^2 + 2\mu n t - n\mu^2).\right\} = \exp\left\{-\frac{1}{2}\sum_{i=1}^n (x_i^2 - t^2)\right\},
</script>
em que <script type="math/tex">S_x^2 = \sum_{i=1}^n x_i^2</script> e <script type="math/tex">X_n = nt - \sum_{i=1}^{n-1} X_i</script>.</p>
<p>Note que podemos escrever 
<script type="math/tex; mode=display">
f(X_1, \dots, X_{n-1} | \bar{X} = t) \propto \exp\left\{nt^2/2\right\}\exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} x_i^2 + \left(nt - \sum_{i=1}^{n-1} x_i\right)^2 \right]\right\} = \exp\left\{nt^2/2\right\}\exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} x_i^2 + n^2t^2 - 2nt\sum_{i=1}^{n-1} x_i + \left(\sum_{i=1}^{n-1} x_i\right)^2\right]\right\}
</script>
</p>
<p>Assim, 
<script type="math/tex; mode=display">
\begin{split}
f(X_1, \dots, X_{n-1} | \bar{X} = t) &\propto \exp\left\{nt^2/2\right\}\exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} (x_i^2 - 2nt x_i + nt^2) +nt^2 + \left(\sum_{i=1}^{n-1} x_i\right)^2\right]\right\} \\
&= \exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} (x_i^2 - 2t x_i + t^2) - 2(n-1)t\sum_{i=1}^{n-1} x_i + (n-1)^2t^2 + \left(\sum_{i=1}^{n-1} x_i\right)^2\right]\right\} \\
&= \exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} (x_i - t)^2 + \left(\sum_{i=1}^{n-1} (x_i - t)\right)^2 \right]\right\} \\
&= \exp\left\{-\frac{1}{2}\left[\sum_{i=1}^{n-1} (x_i - t)^2 + \sum_{j=1}^{n-1} \sum_{i=1}^{n-1} (x_j-t)(x_i - t) \right]\right\}
\end{split}
</script>
</p>
<p>Com isso, observamos que <script type="math/tex">X_1, \dots, X_n | \bar{X} = t</script> tem distribuição Normal Multivariada com <script type="math/tex">\mathbb{E}[X_i] = t</script> para <script type="math/tex">i=1,\dots,n-1</script>
e matriz de covariância (dada pela inversa) 
<script type="math/tex; mode=display">
\Sigma^{-1} = I_{n-1} + \begin{bmatrix}
1 & \cdots & 1 \\
\vdots & \ddots & \vdots \\
1 & \cdots & 1
\end{bmatrix} := I + A
</script>
</p>
<p>Veja que <script type="math/tex">\Sigma = I - A/n</script> (mostre!). </p>
<p>Assim, <script type="math/tex">X_1, \dots, X_{n-1} | \bar{X} = t \sim \operatorname{Normal}((t,\dots,t), I - A/n)</script>.</p>
<p><code>python
mu = 2
n = 10
Sigma = np.eye(n-1) - np.ones((n-1,n-1))/n</code></p>
<p>Façamos um exemplo em que <script type="math/tex">\mu = 2</script> verdadeiro (e desconhecido para os dois estatísticos). Vamos fazer o seguinte experimento <script type="math/tex">M</script> vezes, com <script type="math/tex">M = 100000</script>. Para o primeiro estatístico, oferecemos <script type="math/tex">n</script> amostras. Para o segundo estatístico, só oferecemos a média dessas amostras e ele vai utilizar as contas acima para gerar outras <script type="math/tex">n</script> amostras, isto, ele gerará amostras novas a partir de <script type="math/tex">X_1, \dots, X_{n-1} | \bar{X} = t \sim \operatorname{Normal}((t,\dots,t), I - A/n)</script>, pois ele conhecerá <script type="math/tex">\bar{X}</script>. </p>
<p>Como faremos esses experimentos diversas vezes, vamos obter <script type="math/tex">M</script> amostras de <script type="math/tex">X_1</script> para o estatístico 1, e o estatístico 2 vai produzir outras <script type="math/tex">M</script> a partir da distribuição calculada. Provamos que a distribuição delas será a mesma. Vamos verificar graficamente através do histograma.</p>
<p>```python
mu = 2
n = 10
M = 100000</p>
<p>estatistico1 = np.zeros((M, n))
estatistico2 = np.zeros_like(estatistico1)</p>
<p>for k in tqdm(range(M)):
    x = np.random.normal(loc=mu, scale=1, size=n)
    t = x.mean()</p>
<pre><code>x_fake = np.random.multivariate_normal(mean=t*np.ones(n-1), cov=np.eye(n-1) - np.ones((n-1, n-1))/n)
x_n = n * t - x_fake.sum()
x_fake = np.hstack([x_fake, x_n])

estatistico1[k] = x
estatistico2[k] = x_fake
</code></pre>
<p>```</p>
<pre><code>100%|█████████████████████████████████| 100000/100000 [00:19&lt;00:00, 5034.15it/s]
</code></pre>
<p>Veja que de fato os histogramas são muito similares, como esperávamos! Assim, apenas tendo o valor da média, o estatístico 2 foi capaz de produzir novas amostras a partir da mesma distribuição do estatístico 1!</p>
<p><code>python
plt.hist(estatistico1[:,0], bins=50, label='Estatístico 1')
plt.hist(estatistico2[:,0], alpha=0.5, bins=50, label='Estatístico 2')
plt.title('Comparando a distribuição do dado contra o dado falso')
plt.legend()
plt.show()</code> </p>
<p><img alt="png" src="../output_9_0.png" /></p>
<h3 id="ancilaridade_1">Ancilaridade</h3>
<p>Uma estatística anciliar não depende do parâmetro, então não pode atualizar a informação sobre ele. 
Será que significa que ela pode ser ignorada? 
Vamos verificar isso com um exemplo numérico. Seja <script type="math/tex">X_1, \dots, X_n \overset{iid}{\sim} \operatorname{Unif}[\theta-1/2, \theta+1/2]</script>. Assim 
<script type="math/tex; mode=display">
f(x_1, \dots, x_n | \theta) = \prod_{i=1}^n 1\{\theta -1/2 < x_i < \theta+1/2\} = 1\{\theta - 1/2 < \min\{x_i\}\}1\{\theta + 1/2 > \max\{x_i\}\}
</script>
Portanto <script type="math/tex">T(X) = (\min(X_i), \max(X_i))</script> é estatística suficiente mínima.
Seja <script type="math/tex">U(X) = \max(X_i) - \min(X_i)</script>.
Vamos verificar que <script type="math/tex">U</script> é estatística anciliar </p>
<p>Defina <script type="math/tex">Y_i = X_i - \theta + 1/2 \sim \operatorname{Uniform}(0,1)</script>. Assim, 
<script type="math/tex; mode=display">
U = \max(X_i) - \min(X_i) = \max(X_i-\theta+1/2) - \min(X_i-\theta+1/2) = \max(Y_i) - \min(Y_i).
</script>
Como a distribuição de <script type="math/tex">Y</script> independe de <script type="math/tex">\theta</script>, temos que a distribuição de <script type="math/tex">U</script> também independe, o que mostra que <script type="math/tex">U</script> é estatística anciliar.</p>
<p>Vamos visualizar a distribuição de <script type="math/tex">U</script> de duas formas: partindo de <script type="math/tex">X</script> e partido de <script type="math/tex">Y</script>.</p>
<p>```python
theta = 5
n = 10</p>
<p>X = np.random.uniform(theta-1/2, theta+1/2, size=(100000, n))
Y = np.random.uniform(size=(100000, n))</p>
<h1 id="estamos-tomando-o-maximo-de-cada-linha-de-x-e-obtendo-100000-amostras-para-x">Estamos tomando o máximo de cada linha de X e obtendo 100000 amostras para X.</h1>
<p>U1 = X.max(axis=1) - X.min(axis=1)
U2 = Y.max(axis=1) - Y.min(axis=1)
```</p>
<p>Note que de fato as distribuições são muito similares.</p>
<p><code>python
plt.hist(U1,  bins=50, label='U = max(X_i) - min(X_i)')
plt.hist(U2, alpha=0.5, bins=50, label='U = max(Y_i) - min(Y_i)')
plt.title('Comparando a distribuição de U')
plt.legend()
plt.show()</code></p>
<p><img alt="png" src="../output_13_0.png" /></p>
<p>Se observamos que <script type="math/tex">U(X) = u</script>, podemos calcular que <script type="math/tex">\max(x_i) | U = u \sim \operatorname{Unif}(\theta-1/2+u, \theta+1/2)</script>. 
Assim, a distribuição de uma estatística muda com outra anciliar.</p>
<h2 id="estimadores-aleatorios-e-convexidade">Estimadores aleatórios e convexidade</h2>
<p>O seguinte resultado é a Desigualdade de Jensen:</p>
<blockquote>
<p>Seja <script type="math/tex">I</script> um intervalo aberto tal que <script type="math/tex">\mathbb{P}(X \in I) = 1</script> e <script type="math/tex">f</script> uma <a href="https://en.wikipedia.org/wiki/Convex_function#Definition">função convexa</a>. 
Se <script type="math/tex">X</script> é integrável, então 
<script type="math/tex; mode=display">
f\left(\mathbb{E}[X]\right) \le \mathbb{E}[f(X)].
</script>
Se <script type="math/tex">f</script> é estritamente convexa, a desigualdade é estrita a menos que <script type="math/tex">X</script> seja constante com probabilidade 1.</p>
</blockquote>
<p>Um <strong>estimador randomizado</strong> é um estimador que pode ser construído a partir de uma estatística suficiente <script type="math/tex">T</script> com a geração auxiliar de números aleatórios, isto é, é uma função que mapeia <script type="math/tex">x \in \mathcal{X}</script> a uma variável aleatória <script type="math/tex">Y(x)</script> com distribuição <script type="math/tex">P_x</script>.</p>
<p><strong>Teorema:</strong> Seja <script type="math/tex">X \sim P_{\theta} \in \mathcal{P}</script> e <script type="math/tex">T = T(X)</script> uma estatística suficiente.
Então, para qualquer estimador <script type="math/tex">\phi(X)</script> para <script type="math/tex">g(\theta)</script>, existe um estimador randomizado baseado em <script type="math/tex">T</script> que tem a mesma função de risco de <script type="math/tex">\phi(X)</script>.</p>
<hr />
<p>Ideia da prova: a distribuição de <script type="math/tex">X</script> condicionada em <script type="math/tex">T</script> não depende de <script type="math/tex">\theta</script>, pois <script type="math/tex">T</script> é suficiente.
Seja <script type="math/tex">r(\cdot, T=t)</script> essa distribuição.
Assim, uma variável aleatória <script type="math/tex">Y</script> com essa distribuição tem a mesma distribuição marginal de <script type="math/tex">X</script>, como verificamos <a href="https://lucasmoschen.github.io/ta-sessions/infestatistica_MSc/sufficiency/sufficiency/">aqui</a>. 
Em particular <script type="math/tex">\phi(Y)</script> tem a mesma distribuição de <script type="math/tex">\phi(X)</script>.</p>
<hr />
<h3 id="teorema-de-rao-blackwell">Teorema de Rao-Blackwell</h3>
<p>Sejam <script type="math/tex">T</script> uma estatística suficiente para <script type="math/tex">\theta</script> de uma família de distribuições <script type="math/tex">P_{\theta}</script> e <script type="math/tex">\delta</script> um estimador de <script type="math/tex">g(\theta)</script>.
Defina <script type="math/tex">\eta(T) = \mathbb{E}[\delta(X)|T]</script>.
Se <script type="math/tex">R(\theta, \delta) < +\infty</script>, em que <script type="math/tex">R</script> é a <a href="https://lucasmoschen.github.io/ta-sessions/infestatistica_MSc/risk_function/">função de risco</a> para uma perda <script type="math/tex">L</script>, e <script type="math/tex">L(\theta, \cdot)</script> é convexa, então
<script type="math/tex; mode=display">
R(\theta, \eta) \le R(\theta, \delta).
</script>
Além do mais, se a perda é estritamente convexa, a desigualdade é estrita a menos que <script type="math/tex">\delta(X) = \eta(T)</script> com probabilidade 1.
Esse resultado é uma consequência direta da Desigualdade de Jensen.</p>
<p>Esse resultado mostra que para perdas convexas, sob a ótica do risco apenas, os únicos estimadores interessantes são aqueles que são função de <script type="math/tex">T</script> e não de <script type="math/tex">X</script> (visto que estamos integrando em <script type="math/tex">X</script>).
Além do mais, qualquer estimador randomizado é pior do que o não randomizado tomando a esperança dele condicionada em um estatística suficiente. </p>
<p><em>Observação: <script type="math/tex">\eta(T)</script> é uma estatística, pois não depende de <script type="math/tex">\theta</script>, dado que <script type="math/tex">T</script> é suficiente.</em></p></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../../.."</script>
    
    <script src="../../../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
